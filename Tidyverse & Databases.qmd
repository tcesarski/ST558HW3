---
title: "Tidyverse & Database HW"
format: html
author: "Taylor Cesarski"
warning: false
---
# Task 1: Conceptual Questions

**1. If your working directory is `myfolder/homework` what relative path would you specify to get the file located at `myfolder/MyData.csv` **

>I would use "../MyData.csv"
The ../ moves up one level of the folders back to myfolder and then we are getting the MyData.csv dataset.

**2. What are the major benefits of using R projects? **

>R projects allow us to have a folder that that contains the documents for the task in one convenient location. We can then use git & github to utilize version control, collaborate with others, and use local file paths. R projects allow Git and RStudio to work together!

**3. What is git and what is github? **

>Git is a version control software. It allows you to take snapshots of the folders at different points in time. Github is an online hosting service for Git-based projects that allows us to easily collaborate with others.

**4. What are the two main differences between a tibble and a dataframe?**

>Tibbles print nicer and display the number of observations, columns, etc. They also do not simplify and will return as a tibble, rather than dataframes that could simplify to a vector when subsetting a single column.

**5. Rewrite the following nested function call using baseR's chaining operator. **
Note: I didn't use a block quote on this section because I wanted to use a code chunk.
```{r}

#Original code
library(tidyverse)
arrange(filter(select(as_tibble(iris), starts_with("Petal"), Species), Petal.Length < 1.55), Species)

#Code with chaining
as_tibble(iris) |>
  select(starts_with("Petal"), Species) |>
  filter(Petal.Length < 1.55) |>
  arrange(Species)

```
**6. What is meant by long format data and wide format data? Which do we generally prefer for statistical analysis? **

>Long format is where each row has one observation and each column has a variable.Wide format is where more than one observation may be in a given row. We generally prefer long format for statistical analysis. 

# Task 2: Reading Delimited Data
## Glass Data
I first read in the glass dataset using read_csv because the delimiter is a comma. I then set the column names as given by the variables and printed out the tibble by calling the object name.
```{r}
library(tidyverse)
my_glass_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/glass.data", 
      col_names = c("ID", "RI", "Na", "Mg", "Al", "Si", "K", "Ca", "Ba", "Fe", "Type_of_Glass"))
my_glass_data
```

This code is overwriting the Type_of_Glass variable with the actual names by going through ifelse. First it is seeing if Type_of_Glass is 1, then it is assigning it to building_windows_float_processed. If it is not then it is checking if the Type_of_Glass is 2. If it is then it is assigning it to building_windows_non_float_processed and so forth until it gets to all of the possibilities. If it is not 1-7 then it returns error because all of them are 1-7. After that I filtered to only get obserations where Fe is less than 2 and the Type_of_Glass is tableware or headlamp.
```{r}
my_glass_data |>
  mutate(Type_of_Glass = ifelse(Type_of_Glass == 1, "building_windows_float_processed", 
        ifelse(Type_of_Glass == 2, "building_windows_non_float_processed",
            ifelse(Type_of_Glass == 3, "vehicle_windows_float_processed",
              ifelse(Type_of_Glass == 4, "vehicle_windows_non_float_processed",
                ifelse(Type_of_Glass == 5, "containers",
                  ifelse(Type_of_Glass == 6, "tableware",
                    ifelse(Type_of_Glass == 7, "headlamps",
                           "Error")
        )
        )
        )
        )
        )
        )
        ) |>
  filter(Fe < 0.2 & Type_of_Glass %in% c("tableware", "headlamps"))
```

## Yeast Data
I read in the Yeast Data file. This dataset is a space-delimited file where two spaces are separating each. I opted to use the generic read_delim and then specify the delimiter as two spaces. I also added the column names as given in the table by using col_names().
```{r}
my_yeast_data <- read_delim("https://www4.stat.ncsu.edu/~online/datasets/yeast.data",
           delim = "  ",
         col_names = c("seq_name", "mcg", "gvh", "alm", "mit", "erl", "pox", "vac", "nuc", "class"))
my_yeast_data
```
I then used chaining to first select the columns between mcg and vac and then the class variable. This omits the seq_name column and the nuc columns. Then I grouped by class and added the means and medians at each class grouping using the across function. Since all the columns left were numeric I used is.numeric as was used in the notes and made the names be the mean_columnname and median_columnname.
```{r}
my_yeast_data |>
  select(mcg:vac, class) |>
  group_by(class) |>
  mutate(across(where(is.numeric), mean, .names = "mean_{.col}")) |>
  mutate(across(where(is.numeric), median, .names="median_{.col}"))
```

# Task 2: Combining Excel and Delimited Data
I first downloaded the file and placed it in my working directory. Then I used the read_excel function to read in the dataset and since no sheet was specified, it read in the first sheet. I then read in the second sheet and assigned them to wine_col_names, but this wasn't working correctly initially so I had to use pull() to pull the column called "Variables" and return it as a vector. Then I was able to use the colnames() to assign the new column names based on what was seen in the second sheet of the excel document. Finally, I added a column of Type and set them all to white since these were all white wines.
```{r}
library(readxl)
my_white_wine <- read_excel("white-wine.xlsx")
my_white_wine

wine_col_names <- read_excel("white-wine.xlsx",
                             sheet = 2)
new_col_names <- wine_col_names |>
        pull(Variables)
new_col_names
colnames(my_white_wine) <- new_col_names
my_white_wine

my_white_wine <-
  my_white_wine |>
  mutate(Type = "White")
```

I then read in the red wine dataset using read_csv2() because the delimiter is a semi-colon. I used the same column names above (new_col_names) to assign column names to the red wine dataset. I noticed that some of the variables weren't being read in correctly so I changed them to numeric columns using as.numeric(). Then I added the Type column and set all of them to red since all wines in this dataset are red. I joined these tables together using `dplyr::bind_rows()` and stored that as all_wine_data. Then I filtered the observations to only include wines where the quality was greater than 6.5 and the alcohol is less than 132. Then I arranged the data to sort from highest to lowest by using arrange and desc. Then I selected only the given columns. I then grouped by quality so that when I take the mean and standard deviation that it will respect that grouping. Finally, I added a column called alc_mean and alc_sd that found & printed the means and standard deviations of the alcohol at each setting of the quality variable.
```{r}
my_red_wine <- read_csv2("https://www4.stat.ncsu.edu/~online/datasets/red-wine.csv")
colnames(my_red_wine) <- new_col_names
my_red_wine <- 
  my_red_wine |>
  mutate(volatile_acidity = as.numeric(volatile_acidity),
         citric_acid = as.numeric(citric_acid),
         chlorides = as.numeric(chlorides),
         density = as.numeric(density),
         sulphates = as.numeric(sulphates)) |>
  mutate(Type = "Red")
my_red_wine

all_wine_data <- dplyr::bind_rows(my_white_wine, my_red_wine)

all_wine_data |>
  filter(quality > 6.5 & alcohol < 132) |>
  arrange(desc(quality)) |>
  select(contains("acid"), alcohol, Type, quality) |>
  group_by(quality) |>
  mutate(alc_mean = mean(alcohol),
         alc_sd =sd(alcohol))


```
# Task 3: Database Practice
I downloaded the Lahman database in my working directory and established a connection to the database. I used dbListTables() to look at all the tables in the database. I then used the tbl function to look at the "Teams" table and then only looking at the yearID of 15. Then I did the same thing using the SQL code from the notes. I used collect() so it wouldn't do a lazy evaluation and actually print out everything.
```{r}
library(DBI)
connection <- dbConnect(RSQLite::SQLite(), "lahman.db")
dbListTables(connection)
library(dplyr)
tbl(connection, "Teams") |>
  filter(yearID == 2015) |>
  collect()

#Do with sql function
tbl(connection, sql(
  "SELECT *
  FROM `Teams`
  WHERE (`yearID` == 2015.0)")
)
```
I created a tibble called hall_of_fame by looking at the "Hall of Fame" table and then only selected the inducted to be Y (meaning they actually were inducted). Then I selected only the playerID, yearID, and category variables. Finally, I used collect() so it wouldn't do a lazy evaluation and actually print out everything. Then I created a people tibble that selected the first and last names and the player ID from the "People" table. Finally, I made a people_inducted by doing a left join so that it would take all of the observations from the hall_of_fame tibble and any matching ones from the people tibble and match them with the playerID. My first observation had a playerID of "cobbty01" and a name of Ty Cobb so this seems to have worked correctly.
```{r}
hall_of_fame <-tbl(connection, "HallofFame") |>
  filter(inducted == "Y") |>
  select(playerID, yearID, category) |>
  collect()

hall_of_fame

people <- tbl(connection, "People") |>
  select(nameFirst, nameLast, playerID) |>
  collect()

people

people_inducted <-left_join(hall_of_fame,
          people,
          by = join_by(playerID == playerID))

people_inducted

```
I created a tibble called managers that takes the table called "Managers" and selects only the playerID, G, W, and L columns. I then group by playerID and then created 3 new variables for games managed, total wins, and total losses. I then added a career percentage that takes the total wins and divides it by the games managed. Finally, I arrange the tibble in descending order for the careeer percentage variable.
```{r}
managers <- tbl(connection, "Managers") |>
  select(playerID, G, W, L) |>
  group_by(playerID) |>
  summarize(G_managed = sum(G, na.rm = TRUE),
            Total_W = sum(W, na.rm = TRUE),
            Total_L = sum(L, na.rm = TRUE)) |>
  collect() |>
  mutate(career_percent = Total_W/G_managed) |>
  arrange(desc(career_percent))

managers
```

I used inner join because I wanted the overlap of people that were both managers and were inducted into the hall of fame. I matched using playerID. I double checked that Ty Cobb appeared in both the managers tibble and the people_inducted tibble as a check that it worked correctly.
```{r}
inner_join(people_inducted,
           managers,
           by = join_by(playerID == playerID))
```








